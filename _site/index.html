<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Alaaeldin El-Nouby</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Alaaeldin El-Nouby" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Alaaeldin El-Nouby 
              </h1>
              <p>I am a PhD student (incoming) at <a
                href="https://ai.facebook.com/">Facebook AI Research (FAIR)</a>
                and <a href="https://www.di.ens.fr/">DI ENS</a>/<a
                href="https://www.inria.fr/centre/paris">INRIA Paris</a>, advised
                by <a href="https://www.di.ens.fr/~laptev/">Ivan Laptev</a>, <a
                href="https://nneverova.github.io/">Natalia Neverova</a> and 
              <a href="https://ai.facebook.com/people/herve-jegou">Hervé
              Jégou</a>.</p>
              <p>
                I previously interned at Apple Inc. under the supervision of <a
                href="https://scholar.google.com/citations?user=Sv2TGqsAAAAJ&hl=en">Joshua
                M Susskind  </a> and  <a href="cs.binghamton.edu/~szhai2/">
                Shuangfei Zhai</a>. I have also interned at Microsoft Research
                Montreal under the supervision of <a
                href="https://shikharsharma.com/">Shikhar Sharma</a>. I have
                worked as a Research Engineer at <a
                href="https://www.microsoft.com/en-us/research/group/advanced-technology-lab-cairo-2/">Microsoft
                ATLC</a>
                            </p>
              <p>
                I have a MSc in Computer Engineering from <a
                href="https://www.uoguelph.ca/">University of Guelph</a>, where
                I was advised by <a href="https://www.gwtaylor.ca/">Dr. Graham
                Taylor</a>. During that time, I was a student researcher at the
                <a href="https://vectorinstitute.ai/">Vector Institute</a>.
                            </p>
              <p style="text-align:center">
                <a target="_blank" href="https://mailhide.io/e/ZwOFq"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/aelnouby">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=jxpBMwwAAAA">Google Scholar</a> &nbsp;/&nbsp;
                <a href="http://linkedin.com/in/alaa-el-nouby-1b6496b9"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/alaa_circle_cropped.png">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I'm interested in instance segmentation, image retrieval,
                low-shot learning, video understanding, generative models.              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/skipclip.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Skip-Clip: Self-Supervised Spatiotemporal Representation Learning by Future Clip Order Ranking</h3>
              <br>
              <strong>Alaaeldin El-Nouby</strong>, Shuangfei Zhai, Graham W. Taylor, Joshua M. Susskind

              <br>
              <em>Holistic Video Understanding Workshop ICCV2019 <strong>(Best poster Award)</strong></em>
              <br>
              
              <a href="https://arxiv.org/abs/1910.12770">arxiv</a> /
              
              
              
              
              <a href="static/SkipClip__ICCV_poster.pdf">poster</a> /
              
              
              
              
              <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:wVlGz8mDDl8J:scholar.google.com/&output=citation&scisdr=CgVEUX-mEJL1iATrkuY:AAGBfm0AAAAAXvHuiuZbUT0QQRczLXcApo_VSjD5rSBp&scisig=AAGBfm0AAAAAXvHuihibXdeqwpe64aCTBIFICtClIGe2&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a> /
              
              <p></p>
              <p>We introduce Skip-Clip, a method that utilizes temporal
              coherence in videos, by training a deep model for future clip
              order ranking conditioned on a context clip as a surrogate
              objective for video future prediction. We show that features
              learned using our method are generalizable and transfer strongly
              to downstream tasks.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/GeNeVA.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction</h3>
              <br>
              <strong>Alaaeldin El-Nouby</strong>, Shikhar Sharma, Hannes Schulz, Devon Hjelm, Layla El Asri, Samira Ebrahimi Kahou, Yoshua Bengio, Graham W.Taylor

              <br>
              <em>Proceedings of the 2019 IEEE International Conference on Computer Vision (ICCV)</em>
              <br>
              
              <a href="https://arxiv.org/abs/1811.09845">arxiv</a> /
              
              
              
              <a href="https://github.com/Maluuba/GeNeVA">code</a> /
              
              
              <a href="static/GeNeVA__ICCV_poster.pdf">poster</a> /
              
              
              
              <a href="https://www.microsoft.com/en-us/research/project/generative-neural-visual-artist-geneva/">blog</a> /
              
              
              <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:OX-r6SAfSpgJ:scholar.google.com/&output=citation&scisdr=CgVEUX-mEJL1iATrdlA:AAGBfm0AAAAAXvHublDUgIs3QKmeigWeQNR1LDM6Gf_1&scisig=AAGBfm0AAAAAXvHubtUEcVd1aLhSLOINYoy-9CF2s1rh&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a> /
              
              <p></p>
              <p>In this work, we present a recurrent image
              generation model which takes into account both the generated
              output up to the current step as well as all past instructions for
              generation. We show that our model is able to generate the
              background, add new objects, and apply simple transformations to
              existing objects.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/actionyolo.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Real-Time End-to-End Action Detection with Two-Stream Networks</h3>
              <br>
              <strong>Alaaeldin El-Nouby</strong>, Graham W. Taylor

              <br>
              <em>15th Conference on Computer and Robot Vision, CRV 2018  <strong>(Oral)</strong></em>
              <br>
              
              <a href="https://arxiv.org/abs/1802.08362">arxiv</a> /
              
              
              
              
              
              
              
              <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Us2mO8aop6gJ:scholar.google.com/&output=citation&scisdr=CgVEUX-mEJL1iATrCL8:AAGBfm0AAAAAXvHuEL8aRbNLK0M5DcpLOYe6mN36Oa6S&scisig=AAGBfm0AAAAAXvHuEFFmwXFu7nPGtCNeHNBIk2cpIsZZ&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a> /
              
              <p></p>
              <p>We present a real-time end-to-end trainable two-stream network for action detection. First, we integrate the optical flow computation in our framework by using Flownet2. Second, we apply early fusion for the two streams and train the whole pipeline jointly end-to-end. Finally, for better network initialization, we transfer from the task of action recognition to action detection by pre-training our framework using the recently released large-scale Kinetics dataset.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/thesis.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Spatiotemporal Representation Learning For Human Action Recognition And Localization</h3>
              <br>
              Alaaeldin El-Nouby

              <br>
              <em></em>
              <br>
              
              <a href="https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/17417/ali_alaaeldin_201909_MSc.pdf?sequence=5&isAllowed=y">arxiv</a> /
              
              
              
              
              
              
              
              <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:_SDobe2TbAYJ:scholar.google.com/&output=citation&scisdr=CgVEUX-mEJL1iATqinI:AAGBfm0AAAAAXvHvknKRKKVjO3IF38u0FzHDtoTOxRir&scisig=AAGBfm0AAAAAXvHvkrsnZXcAhNLCbLSZStjvFKfqRSFx&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a> /
              
              <p></p>
              <p>A Thesis presented toThe University of Guelph In partial fulfilment of requirements for the degree of Master of Applied Science in Engineering</p>

            </td>
          </tr>
          
          
          
        </table>
        <br>
        <br>
        <br>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Intel Projects</h2>
              <p>Besides my work on the RealSense depth sensors and the publications above, a sampling of my publicly disclosed work
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
              <p> These include coursework, side projects and unpublished research work. 
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

