---
layout: post
title:  "XCiT: Cross-Covariance Image Transformer"
image: images/xcit_layer.png
categories: research
authors: "<strong>Alaaeldin El-Nouby</strong>, Hugo Touvron, Mathilde Caron, Piotr Bojanowski, Matthijs Douze, Armand Joulin, Ivan Laptev, Natalia Neverova, Gabriel Synnaeve, Jakob Verbeek, Herv√© Jegou
"
venue: "<strong>To appear at NeurIPS 2021</strong>"
arxiv: https://arxiv.org/abs/2106.09681v2
code: https://github.com/facebookresearch/xcit
Yannic Kilcher's Review: https://www.youtube.com/watch?v=g08NkNWmZTA
---
We propose a "transposed" version of self-attention that operates across feature channels rather than tokens. The resulting cross-covariance attention
(XCA) has linear complexity in the number of tokens. Our cross-covariance image transformer (XCiT) is built upon XCA.
It combines the accuracy of conventional transformers with the scalability of convnets. XCiT povides excellent results on multiple vision benchmarks, including image classification and self-supervised feature learning on ImageNet-1k,
object detection and instance segmentation on COCO, and semantic segmentation on ADE20k.
